
<context>
# Overview  
Holistiq is an evidence-based supplement tracking platform that helps users objectively measure the efficacy of cognitive-enhancing supplements (nootropics). While supplement companies make bold claims about improved memory, focus, and cognitive performance, consumers have no reliable way to verify these effects for themselves. Holistiq solves this problem by providing standardized cognitive assessments, supplement tracking, and data visualization to help users determine which supplements actually work for their unique biology.

# Core Features  
1. **Baseline & Follow-up Cognitive Tests**
   - What it does: Provides scientifically-validated cognitive assessment (initially an n-back working memory test)
   - Why it's important: Establishes a reliable baseline and measures cognitive changes over time
   - How it works: Browser-based cognitive test with calibrated timing, administered before supplement use and regularly thereafter

2. **Supplement Intake Logging**
   - What it does: Allows users to record supplement information (name, dosage, timing)
   - Why it's important: Creates the essential exposure data needed to correlate supplement use with cognitive performance
   - How it works: Simple form with calendar view and optional reminder system

3. **Performance Analytics Dashboard**
   - What it does: Visualizes cognitive performance changes compared to baseline
   - Why it's important: Transforms raw test scores into meaningful insights about supplement efficacy
   - How it works: Calculates percentage changes from baseline and presents them in an easy-to-understand chart

4. **User Authentication**
   - What it does: Secures user data and enables return visits
   - Why it's important: Ensures privacy and data continuity
   - How it works: Email-based magic link authentication (passwordless)

5. **Safety Disclaimers**
   - What it does: Provides necessary legal information and educational resources
   - Why it's important: Establishes proper expectations and legal compliance
   - How it works: Modal dialogues and links to authoritative sources

# User Experience  
**User Personas:**
1. **Alex - The Nootropic Enthusiast**: Tech-savvy individual who spends $100-200 monthly on cognitive supplements but is skeptical about actual benefits. Wants evidence-based approaches.
2. **Jamie - The Data-Driven Optimizer**: Tracks multiple aspects of their health and wants quantitative measurements of supplement efficacy to optimize their regimen.
3. **Taylor - The Cautious Starter**: New to supplements and wants to verify benefits before continuing investment.

**Key User Flows:**
1. Onboarding & Baseline Assessment
   - Sign up → Complete baseline cognitive test → View initial results → Log first supplement
   
2. Regular Tracking Cycle
   - Receive reminder → Log supplement intake → Complete follow-up test → View progress dashboard
   
3. Analysis & Adjustment
   - Review performance trends → Compare periods with/without supplements → Adjust supplement regimen based on data

**UI/UX Considerations:**
- Emphasis on simplicity and frictionless interaction
- Clear instructions for test validity (environment, timing, etc.)
- Visual feedback for progress and changes
- Mobile-responsive design for anywhere access
- Minimalist approach focusing only on essential functions
</context>

<PRD>
# Technical Architecture  
## System Components
1. **Frontend Application**
   - Single-page web application with responsive design
   - Test module for cognitive assessments
   - Data visualization components for results display
   - Form components for supplement logging
   - Account management interface

2. **Backend Services**
   - Authentication service
   - User data management
   - Test processing and scoring engine
   - Analytics and calculation service

3. **Database Layer**
   - User profiles table
   - Cognitive test results table
   - Supplement intake records table
   - System configurations and parameters

## Data Models
1. **User Model**
   - Unique identifier
   - Email address
   - Account creation date
   - Settings/preferences

2. **Test Results Model**
   - User ID reference
   - Test type identifier
   - Timestamp
   - Raw score data
   - Calculated metrics
   - Environmental factors (optional)

3. **Supplement Intake Model**
   - User ID reference
   - Supplement name
   - Dosage amount and unit
   - Intake timestamp
   - Notes (optional)

4. **Analytics Model**
   - User ID reference
   - Baseline score references
   - Calculated deltas and percentages
   - Time period markers

## APIs and Integrations
1. **Core Internal APIs**
   - Authentication endpoints
   - User data management endpoints
   - Test processing endpoints
   - Analytics calculation endpoints

2. **Future Integration Points** (not MVP)
   - Health data API hooks (for wearables)
   - Export functionality endpoints
   - Extended test battery integration

## Infrastructure Requirements
1. **Hosting Environment**
   - Web application hosting
   - Database server
   - API server

2. **Performance Requirements**
   - Low-latency test delivery (<100ms)
   - Reliable timing for cognitive tests
   - Secure data storage
   - Regular backups

3. **Security Requirements**
   - Data encryption at rest and in transit
   - Authentication security
   - Compliance with health data regulations

# Development Roadmap  
## Phase 1: Minimum Viable Product
### Frontend
1. **Sign-up and Authentication**
   - Email magic link authentication
   - Basic user profile
   - Access controls

2. **Single Domain Cognitive Test**
   - N-back working memory test implementation
   - Test instructions and environment preparation
   - Test execution interface
   - Results display

3. **Supplement Logging**
   - Basic supplement input form
   - Calendar view of logged supplements
   - Reminder setup interface

4. **Analytics Dashboard**
   - Baseline establishment visualization
   - Delta-vs-baseline chart
   - Basic date filtering

5. **Legal and Safety**
   - Disclaimer implementation
   - Terms of service and privacy policy
   - Educational resources links

### Backend
1. **User Management System**
   - User registration and authentication
   - Profile storage and management

2. **Test Data Processing**
   - Score calculation algorithms
   - Test validity checks
   - Data storage

3. **Supplement Data Management**
   - Intake logging and storage
   - Basic reminder system

4. **Analytics Engine**
   - Baseline determination
   - Delta calculation
   - Simple statistical analysis

## Phase 2: Enhanced User Value
1. **Multi-Domain Cognitive Testing**
   - Additional test types (attention, processing speed, etc.)
   - Composite scoring system
   - Test battery management

2. **Advanced Analytics**
   - Statistical significance indicators
   - Confidence intervals
   - Trend analysis

3. **Supplement Stack Support**
   - Multiple supplement tracking
   - Stack efficacy analysis
   - Interaction tracking

4. **Control Period Features**
   - Washout period tracking
   - Placebo comparison options
   - A/B testing methodology

## Phase 3: Network Effects & Expansion
1. **Community Features**
   - Anonymized benchmarking
   - Performance percentiles
   - Community insights

2. **Advanced Reporting**
   - PDF cognitive reports
   - Data export functionality
   - Detailed historical analysis

3. **External Integrations**
   - Sleep/HRV/activity data imports
   - Professional practitioner sharing
   - Research participation options

4. **Premium Features**
   - Advanced experiment design
   - Comprehensive analysis tools
   - Personalized optimization recommendations

# Logical Dependency Chain
## Foundation Layer (Build First)
1. **Authentication System**
   - User accounts and security are prerequisite for all personalized features
   - Enables data continuity between sessions
   - Critical for privacy protection

2. **Database Structure**
   - Core data models must be established early
   - Defines relationships between users, tests, and supplements
   - Enables all subsequent data operations

3. **Single Cognitive Test Implementation**
   - The n-back test is the foundation of the value proposition
   - Must be properly calibrated for browser environments
   - Requires careful timing implementation

## Quick Win Layer (User-Visible Foundation)
1. **Supplement Logging Interface**
   - Simple form implementation with immediate feedback
   - Calendar visualization of intake
   - Basic reminder functionality

2. **Basic Dashboard**
   - Show test results immediately after completion
   - Simple visualization of baseline and current scores
   - Clear percentage change indicator

3. **Core User Flow Integration**
   - Connect authentication → test → logging → dashboard
   - Enable complete feedback loop for users
   - Validate the fundamental user journey

## Refinement Layer (Building on Foundation)
1. **Analytics Enhancements**
   - Add statistical validity indicators
   - Improve visualization options
   - Implement date range filtering

2. **Test Experience Improvements**
   - Add calibration for device latency
   - Enhance instructions and preparation
   - Implement validity checks for test environment

3. **Supplement Tracking Expansion**
   - Support for multiple supplements
   - Improved calendar visualization
   - Enhanced reminder system

## Extension Layer (Beyond MVP)
1. **Multi-Domain Testing**
   - Additional cognitive tests
   - Composite scoring
   - Domain-specific analytics

2. **Advanced Experiment Design**
   - Control periods
   - Washout tracking
   - A/B comparison tools

3. **Community Features**
   - Benchmarking
   - Anonymized data sharing
   - Comparative analytics

# Risks and Mitigations  
## Technical Challenges
1. **Test Timing Accuracy**
   - Risk: Browser environments have variable latency affecting test validity
   - Mitigation: Implement calibration routine to measure and adjust for device-specific latency
   - Fallback: Clear guidelines for optimal testing conditions

2. **Statistical Significance with Limited Data**
   - Risk: Individual user data may be too sparse for meaningful conclusions
   - Mitigation: Implement confidence intervals and clear uncertainty indicators
   - Fallback: Focus on trend visualization rather than definitive claims

3. **Cross-Browser/Device Compatibility**
   - Risk: Test performance may vary across browsers and devices
   - Mitigation: Standardized testing framework with device detection
   - Fallback: Recommend specific browsers/settings for optimal performance

## MVP Scope Management
1. **Feature Creep**
   - Risk: Adding too many cognitive domains or analytics before validating core
   - Mitigation: Strict adherence to single test + single chart approach for MVP
   - Success Criteria: 40% 4-week retention before expanding features

2. **Data Quality vs. User Friction**
   - Risk: More rigorous testing protocols increase dropout rates
   - Mitigation: Balance scientific validity with user experience
   - Measurement: Track completion rates and adjust protocols accordingly

3. **User Expectations Management**
   - Risk: Users expecting definitive answers about supplement efficacy
   - Mitigation: Clear communication about statistical limitations and n-of-1 approach
   - Education: In-app explanations of how to interpret results properly

## Resource Constraints
1. **Development Prioritization**
   - Risk: Limited resources spread too thin across features
   - Mitigation: Sequential development focusing on core user journey first
   - Process: Regular validation of features against retention metrics

2. **Testing Environment Variability**
   - Risk: Home testing environments introduce uncontrolled variables
   - Mitigation: Capture environmental factors as optional metadata
   - Guidance: Provide best practices for consistent testing conditions

3. **Scientific Credibility Balance**
   - Risk: Oversimplification undermines scientific validity
   - Mitigation: Balance accessible UI with methodological rigor
   - Advisory: Consider scientific advisory input for key methodological decisions

# Appendix  
## Research Findings
1. **Cognitive Testing Validity**
   - N-back tests show strong correlation with working memory performance
   - Test-retest reliability increases with 2+ baseline sessions
   - Environmental factors (time of day, caffeine, sleep) significantly impact scores

2. **Supplement Response Variability**
   - Individual response to nootropics varies significantly
   - Consistent usage patterns crucial for detecting effects
   - Washout periods enhance detection of true effects

3. **User Behavior Patterns**
   - Highest dropout occurs after initial baseline test
   - Engagement increases when visible progress is shown
   - Users prefer simple metrics with clear interpretation

## Technical Specifications
1. **N-back Test Parameters**
   - 2-back and 3-back levels
   - 3-minute test duration
   - Visual-only stimuli for MVP
   - Performance metrics: accuracy percentage, reaction time

2. **Browser Compatibility Requirements**
   - Modern browsers with requestAnimationFrame API
   - Fullscreen API support
   - Local storage capabilities
   - Minimum 60Hz refresh rate recommended

3. **Data Retention Policies**
   - Raw test data: 12 months
   - Calculated metrics: indefinite
   - Supplement logs: indefinite
   - User export capabilities for all data
</PRD>